# ğŸ“š Research Paper Curator - Complete RAG System

A production-ready Retrieval-Augmented Generation (RAG) system for curating, searching, and querying AI research papers from arXiv.

[![CI Pipeline](https://github.com/yourusername/research-paper-curator/workflows/CI%20Pipeline/badge.svg)](https://github.com/yourusername/research-paper-curator/actions)
[![codecov](https://codecov.io/gh/yourusername/research-paper-curator/branch/main/graph/badge.svg)](https://codecov.io/gh/yourusername/research-paper-curator)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)

## ğŸŒŸ Features

### Core Functionality
- **ğŸ¤– Intelligent Q&A**: Ask questions about AI research and get accurate answers with citations
- **ğŸ” Hybrid Search**: Combines vector similarity and keyword search for optimal results
- **ğŸ“„ Paper Management**: Automatic fetching, processing, and indexing of arXiv papers
- **ğŸ’¬ Natural Language Interface**: User-friendly web UI powered by Gradio
- **ğŸš€ High Performance**: Redis caching and optimized vector search

### Technical Highlights
- **Retrieval-Augmented Generation (RAG)** architecture
- **Hybrid Search** with BM25 and vector similarity (cosine)
- **Local LLM** support via Ollama (privacy-focused)
- **Vector Database** with OpenSearch for semantic search
- **PostgreSQL** for structured data and metadata
- **Redis** for caching and performance optimization
- **Apache Airflow** for automated data ingestion
- **Langfuse** for LLM observability and monitoring
- **Docker** support for easy deployment
- **CI/CD** pipeline with GitHub Actions

## ğŸ“‹ Table of Contents

- [Quick Start](#-quick-start)
- [Architecture](#-architecture)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Development](#-development)
- [Deployment](#-deployment)
- [Testing](#-testing)
- [Contributing](#-contributing)
- [License](#-license)

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- PostgreSQL 15+
- Redis 7+
- OpenSearch 2.11+
- Ollama (for LLM)
- Docker (optional, for containerized deployment)

### Quick Installation (Windows)
```powershell
# 1. Clone repository
git clone https://github.com/yourusername/research-paper-curator.git
cd research-paper-curator

# 2. Run setup script
powershell -ExecutionPolicy Bypass -File scripts/setup_windows.ps1

# 3. Configure environment
# Edit .env file with your settings

# 4. Start services with Docker
docker-compose -f docker/docker-compose.yml up -d

# 5. Initialize database
python scripts/setup_db.py

# 6. Seed sample data
python scripts/seed_data.py

# 7. Access the system
# API: http://localhost:8000
# UI: http://localhost:7860
# Airflow: http://localhost:8080
```

### Quick Installation (Linux/Mac)
```bash
# 1. Clone repository
git clone https://github.com/yourusername/research-paper-curator.git
cd research-paper-curator

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
make dev-install

# 4. Configure environment
make setup-env
# Edit .env file

# 5. Start services with Docker
docker-compose -f docker/docker-compose.yml up -d

# 6. Initialize database
make db-init

# 7. Seed data
make db-seed

# 8. Run the application
make run-all
```

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Interface                       â”‚
â”‚                     (Gradio Web UI / API)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI Backend                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Question   â”‚  â”‚    Search    â”‚  â”‚   Ingestion  â”‚     â”‚
â”‚  â”‚  Answering   â”‚  â”‚   Engine     â”‚  â”‚   Pipeline   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                â”‚                â”‚
            â–¼                â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Ollama     â”‚  â”‚  OpenSearch  â”‚  â”‚  PostgreSQL  â”‚
    â”‚    (LLM)     â”‚  â”‚   (Vector)   â”‚  â”‚  (Metadata)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                    â”‚
            â–¼                                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Redis     â”‚                    â”‚   Airflow    â”‚
    â”‚  (Caching)   â”‚                    â”‚ (Scheduling) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Overview

| Component | Purpose | Technology |
|-----------|---------|------------|
| **API Layer** | RESTful API endpoints | FastAPI |
| **UI Layer** | Web interface | Gradio |
| **Search Engine** | Hybrid retrieval | OpenSearch + BM25 |
| **LLM** | Answer generation | Ollama (Llama 2) |
| **Vector Store** | Embeddings storage | OpenSearch |
| **Database** | Metadata & logs | PostgreSQL |
| **Cache** | Performance optimization | Redis |
| **Scheduler** | Automated tasks | Apache Airflow |
| **Embeddings** | Text vectorization | Sentence Transformers |
| **Monitoring** | Observability | Langfuse |

## ğŸ“¦ Installation

### Option 1: Docker (Recommended)
```bash
# Start all services
docker-compose -f docker/docker-compose.yml up -d

# Check status
docker-compose -f docker/docker-compose.yml ps

# View logs
docker-compose -f docker/docker-compose.yml logs -f
```

### Option 2: Local Installation

#### Step 1: Install System Dependencies

**Windows:**
- [Python 3.9+](https://www.python.org/downloads/)
- [PostgreSQL](https://www.postgresql.org/download/windows/)
- [Redis](https://github.com/microsoftarchive/redis/releases)
- [Ollama](https://ollama.ai)

**Linux (Ubuntu/Debian):**
```bash
sudo apt update
sudo apt install python3.11 python3.11-venv postgresql-15 redis-server
```

**macOS:**
```bash
brew install python@3.11 postgresql@15 redis ollama
```

#### Step 2: Install Python Dependencies
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt
pip install -e .
```

#### Step 3: Configure Services

**PostgreSQL:**
```bash
# Create database
createdb research_papers

# Set password (edit .env file)
```

**Redis:**
```bash
# Start Redis
redis-server

# Or as service (Linux)
sudo systemctl start redis
```

**Ollama:**
```bash
# Pull model
ollama pull llama2

# Verify
ollama list
```

**OpenSearch:**
```bash
# Using Docker
docker run -d -p 9200:9200 -e "discovery.type=single-node" \
  -e "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" \
  opensearchproject/opensearch:2.11.0
```

## âš™ï¸ Configuration

### Environment Variables

Create `.env` file from template:
```bash
cp .env.example .env
```

Key configuration options:
```bash
# Application
APP_NAME="Research Paper Curator"
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=research_papers
DB_USER=postgres
DB_PASSWORD=your_password

# OpenSearch
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9200

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama2

# API
API_HOST=0.0.0.0
API_PORT=8000

# UI
UI_PORT=7860
UI_SHARE=false
```

See `.env.example` for all options.

## ğŸ“– Usage

### Starting the System

**Windows:**
```powershell
# Using PowerShell Makefile
.\Makefile.ps1 run-all

# Or manually
# Terminal 1: API
python -m src.api.main

# Terminal 2: UI
python -m src.ui.gradio_interface
```

**Linux/Mac:**
```bash
# Using Makefile
make run-all

# Or manually
# Terminal 1: API
make run-api

# Terminal 2: UI
make run-ui
```

### Using the Web Interface

1. Open browser to `http://localhost:7860`
2. Enter your question in the text box
3. Adjust settings (number of sources, categories)
4. Click "Ask Question"
5. View answer and sources

### Using the API

**Ask a Question:**
```bash
curl -X POST "http://localhost:8000/api/v1/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What are transformers in NLP?",
    "top_k": 5
  }'
```

**Search Papers:**
```bash
curl "http://localhost:8000/api/v1/search?query=attention%20mechanism&top_k=10"
```

**List Papers:**
```bash
curl "http://localhost:8000/api/v1/papers?limit=20&category=cs.AI"
```

**Health Check:**
```bash
curl "http://localhost:8000/api/v1/health/detailed"
```

See [API Documentation](docs/API.md) for complete API reference.

## ğŸ”§ Development

### Project Structure
```
research-paper-curator/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ api/               # FastAPI application
â”‚   â”œâ”€â”€ core/              # Configuration and logging
â”‚   â”œâ”€â”€ database/          # Database models and operations
â”‚   â”œâ”€â”€ embeddings/        # Embedding generation
â”‚   â”œâ”€â”€ retrieval/         # Search engines
â”‚   â”œâ”€â”€ llm/              # LLM integration
â”‚   â”œâ”€â”€ ingestion/        # Data processing
â”‚   â”œâ”€â”€ cache/            # Redis caching
â”‚   â”œâ”€â”€ monitoring/       # Observability
â”‚   â””â”€â”€ ui/               # Gradio interface
â”œâ”€â”€ airflow/              # Airflow DAGs
â”œâ”€â”€ tests/                # Test suite
â”œâ”€â”€ scripts/              # Utility scripts
â”œâ”€â”€ docker/               # Docker configuration
â””â”€â”€ docs/                 # Documentation
```

### Running Tests
```bash
# All tests
make test

# Unit tests only
make test-unit

# Integration tests
make test-integration

# With coverage
make coverage
```

### Code Quality
```bash
# Format code
make format

# Lint code
make lint

# Type checking
make type-check
```

### Adding New Features

1. Create feature branch
2. Implement feature with tests
3. Run code quality checks
4. Submit pull request

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸš¢ Deployment

### Docker Deployment
```bash
# Build images
docker-compose -f docker/docker-compose.yml build

# Start services
docker-compose -f docker/docker-compose.yml up -d

# Scale services
docker-compose -f docker/docker-compose.yml up -d --scale api=3
```

### Production Deployment

See [DEPLOYMENT.md](docs/DEPLOYMENT.md) for:
- Production configuration
- Security hardening
- Performance tuning
- Monitoring setup
- Backup strategies

## ğŸ§ª Testing

### Test Coverage

Current coverage: **85%+**
```bash
# Run with coverage report
pytest tests/ --cov=src --cov-report=html

# View report
open htmlcov/index.html
```

### Test Categories

- **Unit Tests**: Individual component testing
- **Integration Tests**: Component interaction testing
- **End-to-End Tests**: Complete workflow testing

## ğŸ“Š Monitoring

### Available Metrics

- API latency and throughput
- Search performance
- LLM generation time
- Cache hit rates
- Database query performance
- System resource usage

### Monitoring Tools

- **Langfuse**: LLM observability
- **Prometheus**: Metrics collection (optional)
- **Grafana**: Visualization (optional)

## ğŸ¤ Contributing

Contributions are welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details.

### Development Workflow

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [FastAPI](https://fastapi.tiangolo.com/)
- [Gradio](https://gradio.app/)
- [OpenSearch](https://opensearch.org/)
- [Ollama](https://ollama.ai/)
- [Sentence Transformers](https://www.sbert.net/)
- [Apache Airflow](https://airflow.apache.org/)
- [arXiv](https://arxiv.org/)

## ğŸ“§ Contact

Your Name - [@yourtwitter](https://twitter.com/yourtwitter) - email@example.com

Project Link: [https://github.com/yourusername/research-paper-curator](https://github.com/yourusername/research-paper-curator)

---

<p align="center">Made with â¤ï¸ for AI Research</p>