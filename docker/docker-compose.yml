# Docker Compose for Research Paper Curator (Groq version)
# Remove "version" (it's obsolete in newer Docker versions)

# ðŸ‘‡ Add this section to load your .env file automatically

env_file:
  - ../.env

services:
  # ============================================
  # PostgreSQL Database
  # ============================================
  postgres:
    image: postgres:15-alpine
    container_name: rag-postgres
    environment:
      POSTGRES_DB: ${DB_NAME:-research_papers}
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      POSTGRES_INITDB_ARGS: "-E UTF8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "${DB_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # Redis Cache
  # ============================================
  redis:
    image: redis:7-alpine
    container_name: rag-redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "${REDIS_PORT:-6379}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # OpenSearch
  # ============================================
  opensearch:
    image: opensearchproject/opensearch:2.11.0
    container_name: rag-opensearch
    environment:
      - discovery.type=single-node
      - OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m
      - DISABLE_SECURITY_PLUGIN=true
      - "OPENSEARCH_INITIAL_ADMIN_PASSWORD=Admin@123"
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    ports:
      - "${OPENSEARCH_PORT:-9200}:9200"
      - "9600:9600"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # API Service (uses Groq instead of Ollama)
  # ============================================
  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: rag-api
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME:-research_papers}
      - DB_USER=${DB_USER:-postgres}
      - DB_PASSWORD=${DB_PASSWORD:-postgres}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - GROQ_API_KEY=${GROQ_API_KEY}
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
    volumes:
      - ../logs:/app/logs
    ports:
      - "${API_PORT:-8000}:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      opensearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # UI Service (Gradio)
  # ============================================
  ui:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: rag-ui
    environment:
      - API_HOST=api
      - API_PORT=8000
      - UI_PORT=7860
      - UI_SHARE=false
    command: python -m src.ui.gradio_interface
    ports:
      - "${UI_PORT:-7860}:7860"
    depends_on:
      - api
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # Airflow (Optional - for production)
  # ============================================
  airflow-init:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: rag-airflow-init
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/airflow
      - AIRFLOW__CORE__DAGS_FOLDER=/app/airflow/dags
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    command: >
      bash -c "
        pip install apache-airflow==2.8.1 apache-airflow-providers-postgres==5.10.0 &&
        airflow db init &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
      "
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - rag-network

  airflow-webserver:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: rag-airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/airflow
      - AIRFLOW__CORE__DAGS_FOLDER=/app/airflow/dags
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=your_secret_key_here
    command: >
      bash -c "
        pip install apache-airflow==2.8.1 apache-airflow-providers-postgres==5.10.0 &&
        airflow webserver
      "
    ports:
      - "8080:8080"
    depends_on:
      - airflow-init
      - postgres
    volumes:
      - ../airflow:/app/airflow
      - ../logs:/app/logs
    networks:
      - rag-network
    restart: unless-stopped

  airflow-scheduler:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: rag-airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/airflow
      - AIRFLOW__CORE__DAGS_FOLDER=/app/airflow/dags
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    command: >
      bash -c "
        pip install apache-airflow==2.8.1 apache-airflow-providers-postgres==5.10.0 &&
        airflow scheduler
      "
    depends_on:
      - airflow-init
      - postgres
    volumes:
      - ../airflow:/app/airflow
      - ../logs:/app/logs
    networks:
      - rag-network
    restart: unless-stopped

# ============================================
# Networks
# ============================================
networks:
  rag-network:
    driver: bridge

# ============================================
# Volumes
# ============================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  opensearch_data:
    driver: local
