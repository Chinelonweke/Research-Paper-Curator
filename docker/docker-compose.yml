# =============================================================================
# PRODUCTION-READY DOCKER COMPOSE
# Uses optimized base images for PyTorch and Airflow
# =============================================================================

version: '3.8'

networks:
  rag-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  opensearch_data:

services:
  # ============================================
  # PostgreSQL Database
  # ============================================
  postgres:
    image: postgres:15-alpine
    container_name: rag-postgres
    environment:
      POSTGRES_DB: ${DB_NAME:-research_papers}
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      POSTGRES_INITDB_ARGS: "-E UTF8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "${DB_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # Redis Cache
  # ============================================
  redis:
    image: redis:7-alpine
    container_name: rag-redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "${REDIS_PORT:-6379}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # OpenSearch
  # ============================================
  opensearch:
    image: opensearchproject/opensearch:2.11.0
    container_name: rag-opensearch
    environment:
      - discovery.type=single-node
      - OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m
      - DISABLE_SECURITY_PLUGIN=true
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=Admin@123
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    ports:
      - "${OPENSEARCH_PORT:-9200}:9200"
      - "9600:9600"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # API Service (PyTorch base - no torch download!)
  # ============================================
  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile.api
    container_name: rag-api
    env_file:
      - ../.env
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME:-research_papers}
      - DB_USER=${DB_USER:-postgres}
      - DB_PASSWORD=${DB_PASSWORD:-postgres}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - GROQ_API_KEY=${GROQ_API_KEY}
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
    volumes:
      - ../logs:/app/logs
      - ../data:/app/data
    ports:
      - "${API_PORT:-8000}:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      opensearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # UI Service (PyTorch base)
  # ============================================
  ui:
    build:
      context: ..
      dockerfile: docker/Dockerfile.ui
    container_name: rag-ui
    env_file:
      - ../.env
    environment:
      - API_HOST=api
      - API_PORT=8000
      - UI_PORT=7860
      - UI_SHARE=false
    ports:
      - "${UI_PORT:-7860}:7860"
    depends_on:
      - api
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # Airflow Init (Airflow base - no airflow download!)
  # ============================================
  airflow-init:
    build:
      context: ..
      dockerfile: docker/Dockerfile.airflow
    container_name: rag-airflow-init
    env_file:
      - ../.env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/airflow
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
    command: >
      bash -c "
        airflow db init &&
        airflow users create \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com
      "
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - rag-network

  # ============================================
  # Airflow Webserver (Airflow base)
  # ============================================
  airflow-webserver:
    build:
      context: ..
      dockerfile: docker/Dockerfile.airflow
    container_name: rag-airflow-webserver
    env_file:
      - ../.env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/airflow
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=your_secret_key_here_change_in_production
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
    ports:
      - "8080:8080"
    depends_on:
      - airflow-init
      - postgres
    volumes:
      - ../airflow/dags:/opt/airflow/dags
      - ../airflow/logs:/opt/airflow/logs
      - ../airflow/plugins:/opt/airflow/plugins
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    networks:
      - rag-network
    restart: unless-stopped

  # ============================================
  # Airflow Scheduler (Airflow base)
  # ============================================
  airflow-scheduler:
    build:
      context: ..
      dockerfile: docker/Dockerfile.airflow
    container_name: rag-airflow-scheduler
    env_file:
      - ../.env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/airflow
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    depends_on:
      - airflow-init
      - postgres
    volumes:
      - ../airflow/dags:/opt/airflow/dags
      - ../airflow/logs:/opt/airflow/logs
      - ../airflow/plugins:/opt/airflow/plugins
    command: scheduler
    networks:
      - rag-network
    restart: unless-stopped